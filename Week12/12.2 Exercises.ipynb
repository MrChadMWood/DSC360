{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80fe61f6",
   "metadata": {},
   "source": [
    "===========================================\n",
    "\n",
    "Title: 12.2 Exercises\n",
    "\n",
    "Author: Chad Wood\n",
    "\n",
    "Date: 4 Mar 2022\n",
    "\n",
    "Modified By: Chad Wood\n",
    "\n",
    "Description: This program demonstrates building a spacy matcher to identify 'Social Cause' tweets among a large dataset of tweets.\n",
    "\n",
    "==========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac5d4796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "\n",
    "# Loads spacy and customized stop_words \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words.remove('no')\n",
    "stop_words.remove('but')\n",
    "stop_words.remove('not')\n",
    "stop_words.remove('against')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ba16c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Loads data and formats date column\n",
    "data = pd.read_csv('data/tweets.csv').drop(['country'], axis=1)\n",
    "data['date_time'] = pd.to_datetime(data.date_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d1c361d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def normalize(corpus):   \n",
    "    # General Cleansing\n",
    "    corpus = corpus.apply(lambda x: re.sub(r'\\S*https?:\\S*', '', x)) # Removes links\n",
    "    corpus = corpus.apply(lambda x: re.sub(\"@[A-Za-z0-9_]+\", '', x)) # Removes mentions\n",
    "    corpus = corpus.apply(lambda x: re.sub('#([a-zA-Z0-9_]{1,50})', '', x)) # Removes hashtags\n",
    "    corpus = corpus.apply(lambda x: re.sub(r'[^a-zA-z\\s]', '', str(x))) # Removes special characters\n",
    "    corpus = corpus.apply(lambda x: re.sub(' +', ' ', x)) # Removes double+ spaces\n",
    "    corpus = corpus.apply(lambda x: x.strip()) # Removes extra whitspaces\n",
    "\n",
    "    # Runs text through pipeline\n",
    "    clean_list = []\n",
    "    tok_list = []\n",
    "    for doc in nlp.pipe(corpus):\n",
    "        tokens = doc\n",
    "        clean_text = (' '.join(word.lemma_ # Returns roots...\n",
    "                               if word.lemma_ != '-PRON-' # ...Unless POS is pronoun...\n",
    "                               else word.text for word in doc # ...Then returns text for pronouns\n",
    "                               if word.lemma_ not in stop_words)) # Filters stopwords\n",
    "        \n",
    "        tok_list.append(tokens) # Returns tokens\n",
    "        clean_list.append(clean_text) # Returns clean text\n",
    "        \n",
    "    # Clean text to lowercase as Series\n",
    "    clean_Series = pd.Series(clean_list).apply(lambda x: str(x).lower()) \n",
    "    \n",
    "    return clean_Series, pd.Series(tok_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "3212e659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds columns for normalized content and tokens\n",
    "data['clean_content'], data['tokens'] = normalize(data.content)\n",
    "\n",
    "# Removes empty rows\n",
    "data = data.replace('', float('NaN')).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9dd52c",
   "metadata": {},
   "source": [
    "#### Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "c36cadce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_only(matcher, df, col_name):  \n",
    "    # Filters dataframe for rows where matches are found\n",
    "    return df[df[col_name].map(lambda x: len(matcher(x))) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "7211d243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pattern = [\n",
    "    {'LOWER': {'IN': ['justice', 'power', 'poverty', 'prayers', 'the cause', 'movement', 'freedom', 'change']}},\n",
    "    {'LEMMA': {'IN': ['people', 'answer', 'today', 'work', 'deny', 'support', 'enough', 'system']}},\n",
    "    {'POS': {'IN': ['NOUN', 'ADJ', 'ADV']}}\n",
    "]\n",
    "\n",
    "matcher.add('general_cause_words', [pattern])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "85c98aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>date_time</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15911</th>\n",
       "      <td>ladygaga</td>\n",
       "      <td>üôè for no violence during these protests. Be th...</td>\n",
       "      <td>2016-12-11 22:57:00</td>\n",
       "      <td>caitlyn thanku part life amp use platform chan...</td>\n",
       "      <td>(Caitlyn, thanku, for, being, a, part, of, all...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         author                                            content  \\\n",
       "15911  ladygaga  üôè for no violence during these protests. Be th...   \n",
       "\n",
       "                date_time                                      clean_content  \\\n",
       "15911 2016-12-11 22:57:00  caitlyn thanku part life amp use platform chan...   \n",
       "\n",
       "                                                  tokens  \n",
       "15911  (Caitlyn, thanku, for, being, a, part, of, all...  "
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_only(matcher, data, 'tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "530cd89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched: [(11239059035322959770, 4, 7)]\n",
      "Matched: [(11239059035322959770, 4, 7)]\n",
      "Matched: [(11239059035322959770, 6, 9)]\n",
      "Matched: [(11239059035322959770, 8, 11)]\n",
      "Matched: [(11239059035322959770, 10, 13)]\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "def on_match(matcher, doc, id, matches):\n",
    "      print('Matched:', matches)\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "patterns = [nlp('power to the people'), \n",
    "            nlp('roll back poverty'), \n",
    "            nlp('in your prayers')]\n",
    "\n",
    "matcher.add('general_case_phrases', patterns, on_match=on_match)\n",
    "matches = match_only(matcher, data, 'tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "4ba92152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>date_time</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8495</th>\n",
       "      <td>BarackObama</td>\n",
       "      <td>Tune in at 2:30 p.m. ET to watch the President...</td>\n",
       "      <td>2015-01-07 17:56:00</td>\n",
       "      <td>effort roll back poverty roadblock opportunity...</td>\n",
       "      <td>(With, effort, we, can, roll, back, poverty, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9889</th>\n",
       "      <td>rihanna</td>\n",
       "      <td>#Vogue thank you! https://t.co/Aa6uKKtaqc</td>\n",
       "      <td>2016-05-24 01:39:00</td>\n",
       "      <td>please keep joan rivers prayer</td>\n",
       "      <td>(Please, keep, Joan, Rivers, in, your, prayers)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10275</th>\n",
       "      <td>rihanna</td>\n",
       "      <td>friend$hip. in. 2014. http://t.co/GNW8qtuVCF</td>\n",
       "      <td>2014-11-24 22:02:00</td>\n",
       "      <td>please keep people venezuela prayer devastatin...</td>\n",
       "      <td>(Please, keep, the, people, of, Venezuela, in,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10376</th>\n",
       "      <td>rihanna</td>\n",
       "      <td>Burning candles inside of the studio, rappin n...</td>\n",
       "      <td>2014-08-10 06:58:00</td>\n",
       "      <td>navy please keep people philippines prayer i t...</td>\n",
       "      <td>(Navy, please, keep, the, people, of, The, Phi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44865</th>\n",
       "      <td>ArianaGrande</td>\n",
       "      <td>love u back  https://t.co/PCSKZVgkjz</td>\n",
       "      <td>2015-07-13 21:04:00</td>\n",
       "      <td>like ask accompany i prayer important day life...</td>\n",
       "      <td>(I, d, like, to, ask, you, all, to, accompany,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author                                            content  \\\n",
       "8495    BarackObama  Tune in at 2:30 p.m. ET to watch the President...   \n",
       "9889        rihanna          #Vogue thank you! https://t.co/Aa6uKKtaqc   \n",
       "10275       rihanna       friend$hip. in. 2014. http://t.co/GNW8qtuVCF   \n",
       "10376       rihanna  Burning candles inside of the studio, rappin n...   \n",
       "44865  ArianaGrande               love u back  https://t.co/PCSKZVgkjz   \n",
       "\n",
       "                date_time                                      clean_content  \\\n",
       "8495  2015-01-07 17:56:00  effort roll back poverty roadblock opportunity...   \n",
       "9889  2016-05-24 01:39:00                     please keep joan rivers prayer   \n",
       "10275 2014-11-24 22:02:00  please keep people venezuela prayer devastatin...   \n",
       "10376 2014-08-10 06:58:00  navy please keep people philippines prayer i t...   \n",
       "44865 2015-07-13 21:04:00  like ask accompany i prayer important day life...   \n",
       "\n",
       "                                                  tokens  \n",
       "8495   (With, effort, we, can, roll, back, poverty, a...  \n",
       "9889     (Please, keep, Joan, Rivers, in, your, prayers)  \n",
       "10275  (Please, keep, the, people, of, Venezuela, in,...  \n",
       "10376  (Navy, please, keep, the, people, of, The, Phi...  \n",
       "44865  (I, d, like, to, ask, you, all, to, accompany,...  "
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
