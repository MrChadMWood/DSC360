{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbdda08f",
   "metadata": {},
   "source": [
    "===========================================\n",
    "\n",
    "\n",
    "Title: 4.2 Exercises\n",
    "\n",
    "\n",
    "Author: Chad Wood\n",
    "\n",
    "\n",
    "Date: 17 Jan 2021\n",
    "\n",
    "\n",
    "Modified By: Chad Wood\n",
    "\n",
    "\n",
    "Description: This program demonstrates the use of a built module to normalize text and using nlp libraries to determine parts of speech, dependancies, and lemmas\n",
    "\n",
    "\n",
    "=========================================== "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d0bf9c",
   "metadata": {},
   "source": [
    "In the text, there’s a text normalizer created – your assignment is to re-create that normalizer as a Python class that can be re-used (within a .py file). However, unlike the book author’s version, pass a Pandas Series (e.g., dataframe[‘column’]) to your normalize_corpus function and use apply/lambda for each cleaning function. (Ask questions in Teams if that’s unclear.)\n",
    "\n",
    "Using your new text normalizer, create a Jupyter Notebook that uses this class to clean up the text found in the file big.txt (that text file is in the GitHub for Week 4 repository). Your resulting text should be a (long) single stream of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6a663d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import normalizer as nm\n",
    "\n",
    "with open('big.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Creates instance, normalizes, and returns long single stream of text\n",
    "text_series = pd.Series(lines)\n",
    "text_series = nm.Normalizer(text_series)\n",
    "text =  ' '.join(text_series.normalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fd9bffb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Project Gutenberg EBok Adventures Sherlock Holmes Sir Arthur Conan Doyle series Sir Arthur Conan Doyle  copyright law change al world sure check copyright law country download redistribute Project Gutenberg eBok  header first thing sen view project Gutenberg file please remove change edit header without writen permision  please read legal smal print information eBok Project Gutenberg botom file include important information specific right restriction file may use also find make donation Project Gutenberg get involve   welcome World Fre Plain Vanila electronic text  eBoks readable Humans computer since  ebok prepare thousand Volunters   Title Adventures Sherlock Holmes  Author Sir Arthur Conan Doyle  Release Date March [ ebok ] [ recently update November ]  Edition  Language English  Character set encode ascus  START PROJECT GUTENBERG EBOK ADVENTURES SHERLOCK HOLMES     aditional editing Jose Menendez    ADVENTURES SHERLOCK HOLMES    SIR ARTHUR CONAN DOYLE  content  scandal Bohemia RedHeaded League case Ide'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:1021]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf8dc8c",
   "metadata": {},
   "source": [
    "Using spaCy and NLTK, show the tokens, lemmas, parts of speech, and dependencies in the first 1,021 characters of big.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "168f3d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text       POS    Lemma      Dep        POS explained       \n",
      "The        DET    the        det       \n",
      "Project    PROPN  Project    nmod      \n",
      "Gutenberg  PROPN  Gutenberg  npadvmod  \n",
      "EBook      PROPN  EBook      appos     \n",
      "of         ADP    of         prep      \n",
      "The        DET    the        det       \n",
      "Adventures PROPN  Adventures pobj      \n",
      "of         ADP    of         prep      \n",
      "Sherlock   PROPN  Sherlock   compound  \n",
      "Holmes     PROPN  Holmes     pobj      \n",
      "\n",
      "          SPACE  \n",
      "          dep       \n",
      "by         ADP    by         prep      \n",
      "Sir        PROPN  Sir        compound  \n",
      "Arthur     PROPN  Arthur     compound  \n",
      "Conan      PROPN  Conan      compound  \n",
      "Doyle      PROPN  Doyle      pobj      \n",
      "\n",
      "          SPACE  \n",
      "          dep       \n",
      "(          PUNCT  (          punct     \n",
      "#          SYM    #          nmod      \n",
      "15         NUM    15         appos     \n",
      "in         ADP    in         prep      \n",
      "our        PRON   our        poss      \n",
      "series     NOUN   series     pobj      \n",
      "by         ADP    by         prep      \n",
      "Sir        PROPN  Sir        compound  \n",
      "Arthur     PROPN  Arthur     compound  \n",
      "Conan      PROPN  Conan      compound  \n",
      "Doyle      PROPN  Doyle      pobj      \n",
      ")          PUNCT  )          punct     \n",
      "\n",
      " \n",
      "        SPACE  \n",
      " \n",
      "        dep       \n",
      "Copyright  PROPN  Copyright  compound  \n",
      "laws       NOUN   law        nsubj     \n",
      "are        AUX    be         aux       \n",
      "changing   VERB   change     ROOT      \n",
      "all        ADV    all        advmod    \n",
      "over       ADP    over       prep      \n",
      "the        DET    the        det       \n",
      "world      NOUN   world      pobj      \n",
      ".          PUNCT  .          punct     \n",
      "Be         AUX    be         ROOT      \n",
      "sure       ADJ    sure       acomp     \n",
      "to         PART   to         aux       \n",
      "check      VERB   check      xcomp     \n",
      "the        DET    the        det       \n",
      "\n",
      "          SPACE  \n",
      "          dep       \n",
      "copyright  NOUN   copyright  amod      \n",
      "laws       NOUN   law        dobj      \n",
      "for        ADP    for        prep      \n",
      "your       PRON   your       poss      \n",
      "country    NOUN   country    pobj      \n",
      "before     ADP    before     prep      \n",
      "downloading VERB   download   pcomp     \n",
      "or         CCONJ  or         cc        \n",
      "redistributing VERB   redistribute conj      \n",
      "\n",
      "          SPACE  \n",
      "          dep       \n",
      "this       PRON   this       dobj      \n",
      "or         CCONJ  or         cc        \n",
      "any        DET    any        det       \n",
      "other      ADJ    other      amod      \n",
      "Project    PROPN  Project    conj      \n",
      "Gutenberg  PROPN  Gutenberg  compound  \n",
      "eBook      PROPN  eBook      appos     \n",
      ".          PUNCT  .          punct     \n",
      "\n",
      " \n",
      "        SPACE  \n",
      " \n",
      "        dep       \n",
      "This       DET    this       det       \n",
      "header     NOUN   header     nsubj     \n",
      "should     AUX    should     aux       \n",
      "be         AUX    be         ROOT      \n",
      "the        DET    the        det       \n",
      "first      ADJ    first      amod      \n",
      "thing      NOUN   thing      attr      \n",
      "seen       VERB   see        acl       \n",
      "when       SCONJ  when       advmod    \n",
      "viewing    VERB   view       advcl     \n",
      "this       DET    this       det       \n",
      "Project    PROPN  Project    nmod      \n",
      "\n",
      "          SPACE  \n",
      "          dep       \n",
      "Gutenberg  PROPN  Gutenberg  compound  \n",
      "file       NOUN   file       dobj      \n",
      ".          PUNCT  .          punct     \n",
      "           SPACE             dep       \n",
      "Please     INTJ   please     intj      \n",
      "do         AUX    do         aux       \n",
      "not        PART   not        neg       \n",
      "remove     VERB   remove     ROOT      \n",
      "it         PRON   it         dobj      \n",
      ".          PUNCT  .          punct     \n",
      "           SPACE             dep       \n",
      "Do         AUX    do         aux       \n",
      "not        PART   not        neg       \n",
      "change     VERB   change     ROOT      \n",
      "or         CCONJ  or         cc        \n",
      "edit       VERB   edit       conj      \n",
      "the        DET    the        det       \n",
      "\n",
      "          SPACE  \n",
      "          dep       \n",
      "header     NOUN   header     dobj      \n",
      "without    ADP    without    prep      \n",
      "written    VERB   write      amod      \n",
      "permission NOUN   permission pobj      \n",
      ".          PUNCT  .          punct     \n",
      "\n",
      " \n",
      "        SPACE  \n",
      " \n",
      "        dep       \n",
      "Please     INTJ   please     intj      \n",
      "read       VERB   read       ROOT      \n",
      "the        DET    the        det       \n",
      "\"          PUNCT  \"          punct     \n",
      "legal      ADJ    legal      amod      \n",
      "small      ADJ    small      amod      \n",
      "print      NOUN   print      dobj      \n",
      ",          PUNCT  ,          punct     \n",
      "\"          PUNCT  \"          punct     \n",
      "and        CCONJ  and        cc        \n",
      "other      ADJ    other      amod      \n",
      "information NOUN   information conj      \n",
      "about      ADP    about      prep      \n",
      "the        DET    the        det       \n",
      "\n",
      "          SPACE  \n",
      "          dep       \n",
      "eBook      PROPN  eBook      appos     \n",
      "and        CCONJ  and        cc        \n",
      "Project    PROPN  Project    compound  \n",
      "Gutenberg  PROPN  Gutenberg  conj      \n",
      "at         ADP    at         prep      \n",
      "the        DET    the        det       \n",
      "bottom     NOUN   bottom     pobj      \n",
      "of         ADP    of         prep      \n",
      "this       DET    this       det       \n",
      "file       NOUN   file       pobj      \n",
      ".          PUNCT  .          punct     \n",
      "           SPACE             dep       \n",
      "Included   VERB   include    csubj     \n",
      "is         AUX    be         ROOT      \n",
      "\n",
      "          SPACE  \n",
      "          dep       \n",
      "important  ADJ    important  amod      \n",
      "information NOUN   information attr      \n",
      "about      ADP    about      prep      \n",
      "your       PRON   your       poss      \n",
      "specific   ADJ    specific   amod      \n",
      "rights     NOUN   right      pobj      \n",
      "and        CCONJ  and        cc        \n",
      "restrictions NOUN   restriction conj      \n",
      "in         ADP    in         prep      \n",
      "\n",
      "          SPACE  \n",
      "          dep       \n",
      "how        SCONJ  how        advmod    \n",
      "the        DET    the        det       \n",
      "file       NOUN   file       nsubjpass \n",
      "may        AUX    may        aux       \n",
      "be         AUX    be         auxpass   \n",
      "used       VERB   use        relcl     \n",
      ".          PUNCT  .          punct     \n",
      "           SPACE             dep       \n",
      "You        PRON   you        nsubj     \n",
      "can        AUX    can        aux       \n",
      "also       ADV    also       advmod    \n",
      "find       VERB   find       ROOT      \n",
      "out        ADP    out        prt       \n",
      "about      ADP    about      prep      \n",
      "how        SCONJ  how        advmod    \n",
      "to         PART   to         aux       \n",
      "make       VERB   make       pcomp     \n",
      "a          DET    a          det       \n",
      "\n",
      "          SPACE  \n",
      "          dep       \n",
      "donation   NOUN   donation   dobj      \n",
      "to         ADP    to         prep      \n",
      "Project    PROPN  Project    compound  \n",
      "Gutenberg  PROPN  Gutenberg  pobj      \n",
      ",          PUNCT  ,          punct     \n",
      "and        CCONJ  and        cc        \n",
      "how        SCONJ  how        advmod    \n",
      "to         PART   to         aux       \n",
      "get        AUX    get        auxpass   \n",
      "involved   VERB   involve    conj      \n",
      ".          PUNCT  .          punct     \n",
      "\n",
      " \n",
      " \n",
      "      SPACE  \n",
      " \n",
      " \n",
      "      dep       \n",
      "*          PUNCT  *          punct     \n",
      "*          PUNCT  *          punct     \n",
      "Welcome    VERB   welcome    appos     \n",
      "To         ADP    to         prep      \n",
      "The        DET    the        det       \n",
      "World      PROPN  World      pobj      \n",
      "of         ADP    of         prep      \n",
      "Free       PROPN  Free       compound  \n",
      "Plain      PROPN  Plain      compound  \n",
      "Vanilla    PROPN  Vanilla    compound  \n",
      "Electronic ADJ    electronic compound  \n",
      "Texts      PROPN  Texts      pobj      \n",
      "*          PUNCT  *          punct     \n",
      "*          PUNCT  *          punct     \n",
      "\n",
      " \n",
      "        SPACE  \n",
      " \n",
      "        dep       \n",
      "*          PUNCT  *          punct     \n",
      "*          PUNCT  *          punct     \n",
      "eBooks     PROPN  eBooks     compound  \n",
      "Readable   ADJ    readable   appos     \n",
      "By         ADP    by         prep      \n",
      "Both       DET    both       det       \n",
      "Humans     PROPN  Humans     pobj      \n",
      "and        CCONJ  and        cc        \n",
      "By         ADP    by         conj      \n",
      "Computers  NOUN   computer   pobj      \n",
      ",          PUNCT  ,          punct     \n",
      "Since      SCONJ  since      prep      \n",
      "1971       NUM    1971       pobj      \n",
      "*          PUNCT  *          punct     \n",
      "*          PUNCT  *          punct     \n",
      "\n",
      " \n",
      "        SPACE  \n",
      " \n",
      "        dep       \n",
      "*          PUNCT  *          punct     \n",
      "*          PUNCT  *          punct     \n",
      "*          PUNCT  *          punct     \n",
      "*          PUNCT  *          punct     \n",
      "*          PUNCT  *          punct     \n",
      "These      DET    these      det       \n",
      "eBooks     PROPN  eBooks     nsubj     \n",
      "Were       AUX    be         auxpass   \n",
      "Prepared   VERB   prepare    ROOT      \n",
      "By         ADP    by         agent     \n",
      "Thous      ADJ    thous      pobj      \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "txt = ' '.join(lines)[0:1021]\n",
    "doc = nlp(txt)\n",
    "\n",
    "# Prints each piece of Text, Part of Speech, Dependancy, and Explanation\n",
    "print(f\"{'Text':{10}} {'POS':{6}} {'Lemma':{10}} {'Dep':{10}} {'POS explained':{20}}\")\n",
    "for token in doc:\n",
    "    print(f'{token.text:{10}} {token.pos_:{6}} {token.lemma_:{10}} {token.dep_:{10}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f1588057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.parse.corenlp import CoreNLPDependencyParser\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "dep_parser = CoreNLPDependencyParser(url='http://localhost:9000')\n",
    "\n",
    "# Tokenizes text\n",
    "txt = nltk.word_tokenize(' '.join(lines)[0:1021])\n",
    "\n",
    "# Sets objects for each requirement\n",
    "part_os = nltk.pos_tag(txt)\n",
    "lemma = [wordnet_lemmatizer.lemmatize(word) for word in txt]\n",
    "parses = dep_parser.parse(' '.join(lines)[0:1021].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ed444354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word, POS: ('The', 'DT') Lemma: The\n",
      "Word, POS: ('Project', 'NNP') Lemma: Project\n",
      "Word, POS: ('Gutenberg', 'NNP') Lemma: Gutenberg\n",
      "Word, POS: ('EBook', 'NNP') Lemma: EBook\n",
      "Word, POS: ('of', 'IN') Lemma: of\n",
      "Word, POS: ('The', 'DT') Lemma: The\n",
      "Word, POS: ('Adventures', 'NNP') Lemma: Adventures\n",
      "Word, POS: ('of', 'IN') Lemma: of\n",
      "Word, POS: ('Sherlock', 'NNP') Lemma: Sherlock\n",
      "Word, POS: ('Holmes', 'NNP') Lemma: Holmes\n",
      "Word, POS: ('by', 'IN') Lemma: by\n",
      "Word, POS: ('Sir', 'NNP') Lemma: Sir\n",
      "Word, POS: ('Arthur', 'NNP') Lemma: Arthur\n",
      "Word, POS: ('Conan', 'NNP') Lemma: Conan\n",
      "Word, POS: ('Doyle', 'NNP') Lemma: Doyle\n",
      "Word, POS: ('(', '(') Lemma: (\n",
      "Word, POS: ('#', '#') Lemma: #\n",
      "Word, POS: ('15', 'CD') Lemma: 15\n",
      "Word, POS: ('in', 'IN') Lemma: in\n",
      "Word, POS: ('our', 'PRP$') Lemma: our\n",
      "Word, POS: ('series', 'NN') Lemma: series\n",
      "Word, POS: ('by', 'IN') Lemma: by\n",
      "Word, POS: ('Sir', 'NNP') Lemma: Sir\n",
      "Word, POS: ('Arthur', 'NNP') Lemma: Arthur\n",
      "Word, POS: ('Conan', 'NNP') Lemma: Conan\n",
      "Word, POS: ('Doyle', 'NNP') Lemma: Doyle\n",
      "Word, POS: (')', ')') Lemma: )\n",
      "Word, POS: ('Copyright', 'NNP') Lemma: Copyright\n",
      "Word, POS: ('laws', 'NNS') Lemma: law\n",
      "Word, POS: ('are', 'VBP') Lemma: are\n",
      "Word, POS: ('changing', 'VBG') Lemma: changing\n",
      "Word, POS: ('all', 'DT') Lemma: all\n",
      "Word, POS: ('over', 'IN') Lemma: over\n",
      "Word, POS: ('the', 'DT') Lemma: the\n",
      "Word, POS: ('world', 'NN') Lemma: world\n",
      "Word, POS: ('.', '.') Lemma: .\n",
      "Word, POS: ('Be', 'VB') Lemma: Be\n",
      "Word, POS: ('sure', 'JJ') Lemma: sure\n",
      "Word, POS: ('to', 'TO') Lemma: to\n",
      "Word, POS: ('check', 'VB') Lemma: check\n",
      "Word, POS: ('the', 'DT') Lemma: the\n",
      "Word, POS: ('copyright', 'NN') Lemma: copyright\n",
      "Word, POS: ('laws', 'NNS') Lemma: law\n",
      "Word, POS: ('for', 'IN') Lemma: for\n",
      "Word, POS: ('your', 'PRP$') Lemma: your\n",
      "Word, POS: ('country', 'NN') Lemma: country\n",
      "Word, POS: ('before', 'IN') Lemma: before\n",
      "Word, POS: ('downloading', 'VBG') Lemma: downloading\n",
      "Word, POS: ('or', 'CC') Lemma: or\n",
      "Word, POS: ('redistributing', 'VBG') Lemma: redistributing\n",
      "Word, POS: ('this', 'DT') Lemma: this\n",
      "Word, POS: ('or', 'CC') Lemma: or\n",
      "Word, POS: ('any', 'DT') Lemma: any\n",
      "Word, POS: ('other', 'JJ') Lemma: other\n",
      "Word, POS: ('Project', 'NNP') Lemma: Project\n",
      "Word, POS: ('Gutenberg', 'NNP') Lemma: Gutenberg\n",
      "Word, POS: ('eBook', 'NN') Lemma: eBook\n",
      "Word, POS: ('.', '.') Lemma: .\n",
      "Word, POS: ('This', 'DT') Lemma: This\n",
      "Word, POS: ('header', 'NN') Lemma: header\n",
      "Word, POS: ('should', 'MD') Lemma: should\n",
      "Word, POS: ('be', 'VB') Lemma: be\n",
      "Word, POS: ('the', 'DT') Lemma: the\n",
      "Word, POS: ('first', 'JJ') Lemma: first\n",
      "Word, POS: ('thing', 'NN') Lemma: thing\n",
      "Word, POS: ('seen', 'VBN') Lemma: seen\n",
      "Word, POS: ('when', 'WRB') Lemma: when\n",
      "Word, POS: ('viewing', 'VBG') Lemma: viewing\n",
      "Word, POS: ('this', 'DT') Lemma: this\n",
      "Word, POS: ('Project', 'NN') Lemma: Project\n",
      "Word, POS: ('Gutenberg', 'NNP') Lemma: Gutenberg\n",
      "Word, POS: ('file', 'NN') Lemma: file\n",
      "Word, POS: ('.', '.') Lemma: .\n",
      "Word, POS: ('Please', 'VB') Lemma: Please\n",
      "Word, POS: ('do', 'VB') Lemma: do\n",
      "Word, POS: ('not', 'RB') Lemma: not\n",
      "Word, POS: ('remove', 'VB') Lemma: remove\n",
      "Word, POS: ('it', 'PRP') Lemma: it\n",
      "Word, POS: ('.', '.') Lemma: .\n",
      "Word, POS: ('Do', 'NNP') Lemma: Do\n",
      "Word, POS: ('not', 'RB') Lemma: not\n",
      "Word, POS: ('change', 'VB') Lemma: change\n",
      "Word, POS: ('or', 'CC') Lemma: or\n",
      "Word, POS: ('edit', 'VB') Lemma: edit\n",
      "Word, POS: ('the', 'DT') Lemma: the\n",
      "Word, POS: ('header', 'NN') Lemma: header\n",
      "Word, POS: ('without', 'IN') Lemma: without\n",
      "Word, POS: ('written', 'VBN') Lemma: written\n",
      "Word, POS: ('permission', 'NN') Lemma: permission\n",
      "Word, POS: ('.', '.') Lemma: .\n",
      "Word, POS: ('Please', 'VB') Lemma: Please\n",
      "Word, POS: ('read', 'VB') Lemma: read\n",
      "Word, POS: ('the', 'DT') Lemma: the\n",
      "Word, POS: ('``', '``') Lemma: ``\n",
      "Word, POS: ('legal', 'JJ') Lemma: legal\n",
      "Word, POS: ('small', 'JJ') Lemma: small\n",
      "Word, POS: ('print', 'NN') Lemma: print\n",
      "Word, POS: (',', ',') Lemma: ,\n",
      "Word, POS: (\"''\", \"''\") Lemma: ''\n",
      "Word, POS: ('and', 'CC') Lemma: and\n",
      "Word, POS: ('other', 'JJ') Lemma: other\n",
      "Word, POS: ('information', 'NN') Lemma: information\n",
      "Word, POS: ('about', 'IN') Lemma: about\n",
      "Word, POS: ('the', 'DT') Lemma: the\n",
      "Word, POS: ('eBook', 'NN') Lemma: eBook\n",
      "Word, POS: ('and', 'CC') Lemma: and\n",
      "Word, POS: ('Project', 'NNP') Lemma: Project\n",
      "Word, POS: ('Gutenberg', 'NNP') Lemma: Gutenberg\n",
      "Word, POS: ('at', 'IN') Lemma: at\n",
      "Word, POS: ('the', 'DT') Lemma: the\n",
      "Word, POS: ('bottom', 'NN') Lemma: bottom\n",
      "Word, POS: ('of', 'IN') Lemma: of\n",
      "Word, POS: ('this', 'DT') Lemma: this\n",
      "Word, POS: ('file', 'NN') Lemma: file\n",
      "Word, POS: ('.', '.') Lemma: .\n",
      "Word, POS: ('Included', 'NNP') Lemma: Included\n",
      "Word, POS: ('is', 'VBZ') Lemma: is\n",
      "Word, POS: ('important', 'JJ') Lemma: important\n",
      "Word, POS: ('information', 'NN') Lemma: information\n",
      "Word, POS: ('about', 'IN') Lemma: about\n",
      "Word, POS: ('your', 'PRP$') Lemma: your\n",
      "Word, POS: ('specific', 'JJ') Lemma: specific\n",
      "Word, POS: ('rights', 'NNS') Lemma: right\n",
      "Word, POS: ('and', 'CC') Lemma: and\n",
      "Word, POS: ('restrictions', 'NNS') Lemma: restriction\n",
      "Word, POS: ('in', 'IN') Lemma: in\n",
      "Word, POS: ('how', 'WRB') Lemma: how\n",
      "Word, POS: ('the', 'DT') Lemma: the\n",
      "Word, POS: ('file', 'NN') Lemma: file\n",
      "Word, POS: ('may', 'MD') Lemma: may\n",
      "Word, POS: ('be', 'VB') Lemma: be\n",
      "Word, POS: ('used', 'VBN') Lemma: used\n",
      "Word, POS: ('.', '.') Lemma: .\n",
      "Word, POS: ('You', 'PRP') Lemma: You\n",
      "Word, POS: ('can', 'MD') Lemma: can\n",
      "Word, POS: ('also', 'RB') Lemma: also\n",
      "Word, POS: ('find', 'VB') Lemma: find\n",
      "Word, POS: ('out', 'RP') Lemma: out\n",
      "Word, POS: ('about', 'IN') Lemma: about\n",
      "Word, POS: ('how', 'WRB') Lemma: how\n",
      "Word, POS: ('to', 'TO') Lemma: to\n",
      "Word, POS: ('make', 'VB') Lemma: make\n",
      "Word, POS: ('a', 'DT') Lemma: a\n",
      "Word, POS: ('donation', 'NN') Lemma: donation\n",
      "Word, POS: ('to', 'TO') Lemma: to\n",
      "Word, POS: ('Project', 'NNP') Lemma: Project\n",
      "Word, POS: ('Gutenberg', 'NNP') Lemma: Gutenberg\n",
      "Word, POS: (',', ',') Lemma: ,\n",
      "Word, POS: ('and', 'CC') Lemma: and\n",
      "Word, POS: ('how', 'WRB') Lemma: how\n",
      "Word, POS: ('to', 'TO') Lemma: to\n",
      "Word, POS: ('get', 'VB') Lemma: get\n",
      "Word, POS: ('involved', 'VBN') Lemma: involved\n",
      "Word, POS: ('.', '.') Lemma: .\n",
      "Word, POS: ('*', 'JJ') Lemma: *\n",
      "Word, POS: ('*', 'JJ') Lemma: *\n",
      "Word, POS: ('Welcome', 'NNP') Lemma: Welcome\n",
      "Word, POS: ('To', 'TO') Lemma: To\n",
      "Word, POS: ('The', 'DT') Lemma: The\n",
      "Word, POS: ('World', 'NNP') Lemma: World\n",
      "Word, POS: ('of', 'IN') Lemma: of\n",
      "Word, POS: ('Free', 'NNP') Lemma: Free\n",
      "Word, POS: ('Plain', 'NNP') Lemma: Plain\n",
      "Word, POS: ('Vanilla', 'NNP') Lemma: Vanilla\n",
      "Word, POS: ('Electronic', 'NNP') Lemma: Electronic\n",
      "Word, POS: ('Texts', 'NNP') Lemma: Texts\n",
      "Word, POS: ('*', 'NNP') Lemma: *\n",
      "Word, POS: ('*', 'NNP') Lemma: *\n",
      "Word, POS: ('*', 'NNP') Lemma: *\n",
      "Word, POS: ('*', 'NNP') Lemma: *\n",
      "Word, POS: ('eBooks', 'VBZ') Lemma: eBooks\n",
      "Word, POS: ('Readable', 'JJ') Lemma: Readable\n",
      "Word, POS: ('By', 'IN') Lemma: By\n",
      "Word, POS: ('Both', 'DT') Lemma: Both\n",
      "Word, POS: ('Humans', 'NNP') Lemma: Humans\n",
      "Word, POS: ('and', 'CC') Lemma: and\n",
      "Word, POS: ('By', 'IN') Lemma: By\n",
      "Word, POS: ('Computers', 'NNP') Lemma: Computers\n",
      "Word, POS: (',', ',') Lemma: ,\n",
      "Word, POS: ('Since', 'IN') Lemma: Since\n",
      "Word, POS: ('1971', 'CD') Lemma: 1971\n",
      "Word, POS: ('*', 'NNP') Lemma: *\n",
      "Word, POS: ('*', 'NNP') Lemma: *\n",
      "Word, POS: ('*', 'NNP') Lemma: *\n",
      "Word, POS: ('*', 'NNP') Lemma: *\n",
      "Word, POS: ('*', 'NNP') Lemma: *\n",
      "Word, POS: ('*', 'NNP') Lemma: *\n",
      "Word, POS: ('*', 'NNP') Lemma: *\n",
      "Word, POS: ('These', 'DT') Lemma: These\n",
      "Word, POS: ('eBooks', 'NNS') Lemma: eBooks\n",
      "Word, POS: ('Were', 'RB') Lemma: Were\n",
      "Word, POS: ('Prepared', 'VBN') Lemma: Prepared\n",
      "Word, POS: ('By', 'IN') Lemma: By\n",
      "Word, POS: ('Thous', 'JJ') Lemma: Thous\n"
     ]
    }
   ],
   "source": [
    "for pos, lem in zip(part_os, lemma):\n",
    "    print(f\"Word, POS: {pos} Lemma: {lem}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ffff3245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependancies\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[(('changing', 'VBG'), 'nsubj', ('EBook', 'NNP')),\n",
       "  (('EBook', 'NNP'), 'det', ('The', 'DT')),\n",
       "  (('EBook', 'NNP'), 'compound', ('Project', 'NN')),\n",
       "  (('EBook', 'NNP'), 'compound', ('Gutenberg', 'NNP')),\n",
       "  (('EBook', 'NNP'), 'nmod', ('Adventures', 'NNS')),\n",
       "  (('Adventures', 'NNS'), 'case', ('of', 'IN')),\n",
       "  (('Adventures', 'NNS'), 'det', ('The', 'DT')),\n",
       "  (('Adventures', 'NNS'), 'nmod', ('Holmes', 'NNP')),\n",
       "  (('Holmes', 'NNP'), 'case', ('of', 'IN')),\n",
       "  (('Holmes', 'NNP'), 'compound', ('Sherlock', 'NNP')),\n",
       "  (('EBook', 'NNP'), 'nmod', ('Doyle', 'NNP')),\n",
       "  (('Doyle', 'NNP'), 'case', ('by', 'IN')),\n",
       "  (('Doyle', 'NNP'), 'compound', ('Sir', 'NNP')),\n",
       "  (('Doyle', 'NNP'), 'compound', ('Arthur', 'NNP')),\n",
       "  (('Doyle', 'NNP'), 'compound', ('Conan', 'NNP')),\n",
       "  (('Doyle', 'NNP'), 'dep', ('15', 'CD')),\n",
       "  (('15', 'CD'), 'punct', ('-LRB-', '-LRB-')),\n",
       "  (('15', 'CD'), 'dep', ('#', '#')),\n",
       "  (('15', 'CD'), 'nmod', ('series', 'NN')),\n",
       "  (('series', 'NN'), 'case', ('in', 'IN')),\n",
       "  (('series', 'NN'), 'nmod:poss', ('our', 'PRP$')),\n",
       "  (('series', 'NN'), 'nmod', ('Doyle', 'NNP')),\n",
       "  (('Doyle', 'NNP'), 'case', ('by', 'IN')),\n",
       "  (('Doyle', 'NNP'), 'compound', ('Sir', 'NNP')),\n",
       "  (('Doyle', 'NNP'), 'compound', ('Arthur', 'NNP')),\n",
       "  (('Doyle', 'NNP'), 'compound', ('Conan', 'NNP')),\n",
       "  (('15', 'CD'), 'punct', ('-RRB-', '-RRB-')),\n",
       "  (('changing', 'VBG'), 'nsubj', ('laws', 'NNS')),\n",
       "  (('laws', 'NNS'), 'compound', ('Copyright', 'NN')),\n",
       "  (('changing', 'VBG'), 'aux', ('are', 'VBP')),\n",
       "  (('changing', 'VBG'), 'nmod', ('world', 'NN')),\n",
       "  (('world', 'NN'), 'dep', ('all', 'DT')),\n",
       "  (('world', 'NN'), 'case', ('over', 'IN')),\n",
       "  (('world', 'NN'), 'det', ('the', 'DT')),\n",
       "  (('changing', 'VBG'), 'punct', ('.', '.')),\n",
       "  (('changing', 'VBG'), 'parataxis', ('sure', 'JJ')),\n",
       "  (('sure', 'JJ'), 'cop', ('Be', 'VB')),\n",
       "  (('sure', 'JJ'), 'xcomp', ('check', 'VB')),\n",
       "  (('check', 'VB'), 'mark', ('to', 'TO')),\n",
       "  (('check', 'VB'), 'dobj', ('laws', 'NNS')),\n",
       "  (('laws', 'NNS'), 'det', ('the', 'DT')),\n",
       "  (('laws', 'NNS'), 'compound', ('copyright', 'NN')),\n",
       "  (('laws', 'NNS'), 'nmod', ('country', 'NN')),\n",
       "  (('country', 'NN'), 'case', ('for', 'IN')),\n",
       "  (('country', 'NN'), 'nmod:poss', ('your', 'PRP$')),\n",
       "  (('check', 'VB'), 'advcl', ('downloading', 'VBG')),\n",
       "  (('downloading', 'VBG'), 'mark', ('before', 'IN')),\n",
       "  (('downloading', 'VBG'), 'cc', ('or', 'CC')),\n",
       "  (('downloading', 'VBG'), 'conj', ('redistributing', 'VBG')),\n",
       "  (('downloading', 'VBG'), 'dobj', ('this', 'DT')),\n",
       "  (('this', 'DT'), 'cc', ('or', 'CC')),\n",
       "  (('this', 'DT'), 'conj', ('eBook', 'NNP')),\n",
       "  (('eBook', 'NNP'), 'det', ('any', 'DT')),\n",
       "  (('eBook', 'NNP'), 'amod', ('other', 'JJ')),\n",
       "  (('eBook', 'NNP'), 'compound', ('Project', 'NN')),\n",
       "  (('eBook', 'NNP'), 'compound', ('Gutenberg', 'NNP')),\n",
       "  (('changing', 'VBG'), 'punct', ('.', '.')),\n",
       "  (('changing', 'VBG'), 'parataxis', ('thing', 'NN')),\n",
       "  (('thing', 'NN'), 'nsubj', ('header', 'NN')),\n",
       "  (('header', 'NN'), 'det', ('This', 'DT')),\n",
       "  (('thing', 'NN'), 'aux', ('should', 'MD')),\n",
       "  (('thing', 'NN'), 'cop', ('be', 'VB')),\n",
       "  (('thing', 'NN'), 'det', ('the', 'DT')),\n",
       "  (('thing', 'NN'), 'amod', ('first', 'JJ')),\n",
       "  (('thing', 'NN'), 'acl', ('seen', 'VBN')),\n",
       "  (('seen', 'VBN'), 'advcl', ('viewing', 'VBG')),\n",
       "  (('viewing', 'VBG'), 'advmod', ('when', 'WRB')),\n",
       "  (('viewing', 'VBG'), 'dobj', ('file', 'NN')),\n",
       "  (('file', 'NN'), 'det', ('this', 'DT')),\n",
       "  (('file', 'NN'), 'compound', ('Project', 'NN')),\n",
       "  (('file', 'NN'), 'compound', ('Gutenberg', 'NNP')),\n",
       "  (('changing', 'VBG'), 'punct', ('.', '.')),\n",
       "  (('changing', 'VBG'), 'parataxis', ('remove', 'VB')),\n",
       "  (('remove', 'VB'), 'discourse', ('Please', 'UH')),\n",
       "  (('remove', 'VB'), 'aux', ('do', 'VB')),\n",
       "  (('remove', 'VB'), 'neg', ('not', 'RB')),\n",
       "  (('remove', 'VB'), 'dobj', ('it', 'PRP')),\n",
       "  (('changing', 'VBG'), 'punct', ('.', '.')),\n",
       "  (('changing', 'VBG'), 'parataxis', ('change', 'VB')),\n",
       "  (('change', 'VB'), 'aux', ('Do', 'VBP')),\n",
       "  (('change', 'VB'), 'neg', ('not', 'RB')),\n",
       "  (('change', 'VB'), 'cc', ('or', 'CC')),\n",
       "  (('change', 'VB'), 'conj', ('edit', 'VB')),\n",
       "  (('change', 'VB'), 'dobj', ('header', 'NN')),\n",
       "  (('header', 'NN'), 'det', ('the', 'DT')),\n",
       "  (('change', 'VB'), 'nmod', ('permission', 'NN')),\n",
       "  (('permission', 'NN'), 'case', ('without', 'IN')),\n",
       "  (('permission', 'NN'), 'amod', ('written', 'VBN')),\n",
       "  (('changing', 'VBG'), 'punct', ('.', '.')),\n",
       "  (('changing', 'VBG'), 'parataxis', ('read', 'VB')),\n",
       "  (('read', 'VB'), 'discourse', ('Please', 'UH')),\n",
       "  (('read', 'VB'), 'dobj', ('print', 'NN')),\n",
       "  (('print', 'NN'), 'det', ('the', 'DT')),\n",
       "  (('print', 'NN'), 'punct', ('``', '``')),\n",
       "  (('print', 'NN'), 'amod', ('legal', 'JJ')),\n",
       "  (('print', 'NN'), 'amod', ('small', 'JJ')),\n",
       "  (('changing', 'VBG'), 'punct', (',', ',')),\n",
       "  (('changing', 'VBG'), 'punct', (\"''\", \"''\")),\n",
       "  (('changing', 'VBG'), 'cc', ('and', 'CC')),\n",
       "  (('changing', 'VBG'), 'conj', ('information', 'NN')),\n",
       "  (('information', 'NN'), 'amod', ('other', 'JJ')),\n",
       "  (('information', 'NN'), 'nmod', ('eBook', 'NNP')),\n",
       "  (('eBook', 'NNP'), 'case', ('about', 'IN')),\n",
       "  (('eBook', 'NNP'), 'det', ('the', 'DT')),\n",
       "  (('eBook', 'NNP'), 'cc', ('and', 'CC')),\n",
       "  (('eBook', 'NNP'), 'conj', ('Gutenberg', 'NNP')),\n",
       "  (('Gutenberg', 'NNP'), 'compound', ('Project', 'NNP')),\n",
       "  (('information', 'NN'), 'nmod', ('bottom', 'NN')),\n",
       "  (('bottom', 'NN'), 'case', ('at', 'IN')),\n",
       "  (('bottom', 'NN'), 'det', ('the', 'DT')),\n",
       "  (('bottom', 'NN'), 'nmod', ('file', 'NN')),\n",
       "  (('file', 'NN'), 'case', ('of', 'IN')),\n",
       "  (('file', 'NN'), 'det', ('this', 'DT')),\n",
       "  (('information', 'NN'), 'punct', ('.', '.')),\n",
       "  (('information', 'NN'), 'acl:relcl', ('information', 'NN')),\n",
       "  (('information', 'NN'), 'nsubj', ('Included', 'VBN')),\n",
       "  (('information', 'NN'), 'cop', ('is', 'VBZ')),\n",
       "  (('information', 'NN'), 'amod', ('important', 'JJ')),\n",
       "  (('information', 'NN'), 'nmod', ('rights', 'NNS')),\n",
       "  (('rights', 'NNS'), 'case', ('about', 'IN')),\n",
       "  (('rights', 'NNS'), 'nmod:poss', ('your', 'PRP$')),\n",
       "  (('rights', 'NNS'), 'amod', ('specific', 'JJ')),\n",
       "  (('rights', 'NNS'), 'cc', ('and', 'CC')),\n",
       "  (('rights', 'NNS'), 'conj', ('restrictions', 'NNS')),\n",
       "  (('rights', 'NNS'), 'acl', ('used', 'VBN')),\n",
       "  (('used', 'VBN'), 'mark', ('in', 'IN')),\n",
       "  (('used', 'VBN'), 'advmod', ('how', 'WRB')),\n",
       "  (('used', 'VBN'), 'nsubjpass', ('file', 'NN')),\n",
       "  (('file', 'NN'), 'det', ('the', 'DT')),\n",
       "  (('used', 'VBN'), 'aux', ('may', 'MD')),\n",
       "  (('used', 'VBN'), 'auxpass', ('be', 'VB')),\n",
       "  (('changing', 'VBG'), 'punct', ('.', '.')),\n",
       "  (('changing', 'VBG'), 'conj', ('find', 'VB')),\n",
       "  (('find', 'VB'), 'nsubj', ('You', 'PRP')),\n",
       "  (('find', 'VB'), 'aux', ('can', 'MD')),\n",
       "  (('find', 'VB'), 'advmod', ('also', 'RB')),\n",
       "  (('find', 'VB'), 'compound:prt', ('out', 'RP')),\n",
       "  (('find', 'VB'), 'advcl', ('make', 'VB')),\n",
       "  (('make', 'VB'), 'mark', ('about', 'IN')),\n",
       "  (('make', 'VB'), 'advmod', ('how', 'WRB')),\n",
       "  (('make', 'VB'), 'mark', ('to', 'TO')),\n",
       "  (('make', 'VB'), 'dobj', ('donation', 'NN')),\n",
       "  (('donation', 'NN'), 'det', ('a', 'DT')),\n",
       "  (('donation', 'NN'), 'nmod', ('Gutenberg', 'NNP')),\n",
       "  (('Gutenberg', 'NNP'), 'case', ('to', 'TO')),\n",
       "  (('Gutenberg', 'NNP'), 'compound', ('Project', 'NNP')),\n",
       "  (('changing', 'VBG'), 'punct', (',', ',')),\n",
       "  (('changing', 'VBG'), 'cc', ('and', 'CC')),\n",
       "  (('changing', 'VBG'), 'conj', ('get', 'VB')),\n",
       "  (('get', 'VB'), 'advmod', ('how', 'WRB')),\n",
       "  (('get', 'VB'), 'mark', ('to', 'TO')),\n",
       "  (('get', 'VB'), 'xcomp', ('involved', 'VBN')),\n",
       "  (('changing', 'VBG'), 'punct', ('.', '.')),\n",
       "  (('changing', 'VBG'), 'punct', ('**', 'SYM')),\n",
       "  (('**', 'SYM'), 'root', ('Texts', 'VBZ')),\n",
       "  (('Texts', 'VBZ'), 'nsubj', ('Welcome', 'UH')),\n",
       "  (('Welcome', 'UH'), 'nmod', ('World', 'NN')),\n",
       "  (('World', 'NN'), 'case', ('To', 'TO')),\n",
       "  (('World', 'NN'), 'det', ('The', 'DT')),\n",
       "  (('World', 'NN'), 'nmod', ('Electronic', 'NNP')),\n",
       "  (('Electronic', 'NNP'), 'case', ('of', 'IN')),\n",
       "  (('Electronic', 'NNP'), 'compound', ('Free', 'NNP')),\n",
       "  (('Electronic', 'NNP'), 'compound', ('Plain', 'NNP')),\n",
       "  (('Electronic', 'NNP'), 'compound', ('Vanilla', 'NNP')),\n",
       "  (('Texts', 'VBZ'), 'dobj', ('**', 'SYM')),\n",
       "  (('**', 'SYM'), 'dep', ('**', 'SYM')),\n",
       "  (('**', 'SYM'), 'root', ('eBooks', 'NNPS')),\n",
       "  (('eBooks', 'NNPS'), 'amod', ('Readable', 'JJ')),\n",
       "  (('Readable', 'JJ'), 'nmod', ('Humans', 'NNS')),\n",
       "  (('Humans', 'NNS'), 'case', ('By', 'IN')),\n",
       "  (('Humans', 'NNS'), 'cc:preconj', ('Both', 'CC')),\n",
       "  (('Humans', 'NNS'), 'cc', ('and', 'CC')),\n",
       "  (('Humans', 'NNS'), 'conj', ('Computers', 'NNS')),\n",
       "  (('Computers', 'NNS'), 'case', ('By', 'IN')),\n",
       "  (('eBooks', 'NNPS'), 'punct', (',', ',')),\n",
       "  (('eBooks', 'NNPS'), 'dep', ('Since', 'IN')),\n",
       "  (('Since', 'IN'), 'dep', ('eBooks', 'NNS')),\n",
       "  (('eBooks', 'NNS'), 'nummod', ('*****', 'CD')),\n",
       "  (('*****', 'CD'), 'compound', ('1971', 'CD')),\n",
       "  (('*****', 'CD'), 'dep', ('**', 'SYM')),\n",
       "  (('eBooks', 'NNS'), 'det', ('These', 'DT')),\n",
       "  (('eBooks', 'NNS'), 'acl', ('Were', 'VBD')),\n",
       "  (('Were', 'VBD'), 'xcomp', ('Prepared', 'JJ')),\n",
       "  (('Prepared', 'JJ'), 'nmod', ('Thous', 'JJ')),\n",
       "  (('Thous', 'JJ'), 'case', ('By', 'IN'))]]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Dependancies')\n",
    "[[(governor, dep, dependent) for governor, dep, dependent in parse.triples()] for parse in parses]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
