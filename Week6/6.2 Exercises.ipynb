{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a662dd1a",
   "metadata": {},
   "source": [
    "===========================================\n",
    "\n",
    "\n",
    "Title: 6.2 Exercises\n",
    "\n",
    "\n",
    "Author: Chad Wood\n",
    "\n",
    "\n",
    "Date: 28 Jan 2022\n",
    "\n",
    "\n",
    "Modified By: Chad Wood\n",
    "\n",
    "\n",
    "Description: This program demonstrates building and using a logistic regression machine learning model that uses multiple feature engineering techniques to classify a Amazon reviews as either positive or negative.\n",
    "\n",
    "\n",
    "=========================================== "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d69561",
   "metadata": {},
   "source": [
    "## 6.2 Exercises\n",
    "\n",
    "<b>(1) Using the Amazon Alexa reviews dataset, build a logistic regression model to predict positive or negative feedback based on review text. Be sure to run a test with something random you create (out of sample). Remember: 1 is positive, 0 is negative.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b295f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lib.normalizer as nm\n",
    "import nltk\n",
    "\n",
    "# Allows no/not to be retained through normalization\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')\n",
    "\n",
    "data = pd.read_csv('data/amazon_alexa.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7967efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizes data\n",
    "verified_reviews = nm.Normalizer(data['verified_reviews'])\n",
    "data['verified_reviews'] = verified_reviews.normalize(\n",
    "    strip_html=True, remove_special_chars=True, \n",
    "    remove_digits=True, remove_stopwords=True,\n",
    "    remove_accented_chars=True, expand_contractions=True,\n",
    "    lemmatize_text=True, text_lower=True,\n",
    "    stopwords=stopword_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "396e6644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3150 entries, 0 to 3149\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   rating            3150 non-null   int64 \n",
      " 1   date              3150 non-null   object\n",
      " 2   variation         3150 non-null   object\n",
      " 3   verified_reviews  3150 non-null   object\n",
      " 4   feedback          3150 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 123.2+ KB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Drops nan rows\n",
    "data = data.dropna().reset_index(drop=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844e223e",
   "metadata": {},
   "source": [
    "### <i> Below is my initial take, before realizing the book walks us through the process.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1835042a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Attempts to use BOW Feature Model for ML Model\n",
    "def bow(corpus):\n",
    "    # Gets bag of words features\n",
    "    cv = CountVectorizer(min_df=0., max_df=1.)\n",
    "    cv_X = cv.fit_transform(corpus)\n",
    "    cv_names = cv.get_feature_names()\n",
    "\n",
    "    return pd.DataFrame(cv_X.toarray(), columns=cv_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c45061e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Gets BOW Model of corpus\n",
    "corpus_model = bow(data['verified_reviews'])\n",
    "\n",
    "# Splits data into training/testing pairs\n",
    "train_corpus, test_corpus, train_label_nums, test_label_nums = train_test_split(np.array(corpus_model),\n",
    "                                                                                np.array(data['feedback']),\n",
    "                                                                                test_size=0.35, random_state=42)\n",
    "\n",
    "# Builds ML the model, trains it with corpus\n",
    "logistic = linear_model.LogisticRegression()\n",
    "logistic.fit(train_corpus, train_label_nums)\n",
    "\n",
    "# Predicts rating values\n",
    "y_pred = logistic.predict(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "558c2ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Predicted:    \n",
      "                   1   0\n",
      "Actual: 1        991   9\n",
      "        0         66  37\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(meu) # Updated book module due to pd.MultiIndex using labels arg\n",
    "                      # labels arg changed to codes\n",
    "# import lib.model_evaluation_utils as meu\n",
    "\n",
    "# Generates confusion matrix\n",
    "meu.display_confusion_matrix(true_labels=test_label_nums, predicted_labels=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3902fba9",
   "metadata": {},
   "source": [
    "<i><b>\"Be sure to run a test with something random you create (out of sample).\" :</b></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "981575a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Predicted:   \n",
      "                   1  0\n",
      "Actual: 1          1  0\n",
      "        0          1  0\n"
     ]
    }
   ],
   "source": [
    "# Builds sample\n",
    "sample = ['not fan write review not meet expectation',\n",
    "          'really love write test review']\n",
    "sample_label = [0, 1]\n",
    "\n",
    "# Gets BOW Model of sample\n",
    "bow(sample)\n",
    "\n",
    "# Creates compatible DF\n",
    "tmp = pd.DataFrame(corpus_model.columns).set_index(0).T\n",
    "tmp['drop_this_col'] = 0,0 # Adds two rows to DF\n",
    "tmp = tmp.fillna(0).drop(columns=['drop_this_col'])\n",
    "\n",
    "# Adds sample to DF\n",
    "for string, row in zip(sample, range(2)):\n",
    "    for word in string.split():\n",
    "        tmp[word].iloc[row] = 1\n",
    "\n",
    "sample_corpus = np.array(tmp)\n",
    "sample_label = np.array(sample_label)\n",
    "\n",
    "# Predicts and displays confusion matrix\n",
    "sample_pred = logistic.predict(sample_corpus)\n",
    "meu.display_confusion_matrix(true_labels=sample_label, predicted_labels=sample_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d36131f",
   "metadata": {},
   "source": [
    "### <i> Below is my second take, following the books guide (pg 315+).</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6ae279d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Splits data into training/testing pairs\n",
    "train_corpus, test_corpus, train_label_nums, test_label_nums = train_test_split(np.array(data['verified_reviews']),\n",
    "                                                                                np.array(data['feedback']),\n",
    "                                                                                test_size=0.35, random_state=42)\n",
    "\n",
    "# builds BOW features\n",
    "cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0)\n",
    "cv_train_features = cv.fit_transform(train_corpus)\n",
    "\n",
    "# transforms test_corpus into features\n",
    "cv_test_features = cv.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4e6cb566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.92682927 0.94634146 0.92665037 0.93887531 0.93154034]\n",
      "Average CV Accuracy: 0.9340473492754487\n",
      "Test Accuracy: 0.9320036264732547\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "log_reg = linear_model.LogisticRegression(penalty='l2', max_iter=100, C=1, random_state=42)\n",
    "log_reg.fit(cv_train_features, train_label_nums)\n",
    "\n",
    "# Gets CV accuracy\n",
    "lr_bow_cv_scores = cross_val_score(log_reg, cv_train_features, train_label_nums, cv=5)\n",
    "lr_bow_cv_mean_score = np.mean(lr_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', lr_bow_cv_scores) # 5-fold\n",
    "print('Average CV Accuracy:', lr_bow_cv_mean_score) # Average\n",
    "\n",
    "# Model test accuracy\n",
    "lr_bow_test_score = log_reg.score(cv_test_features, test_label_nums)\n",
    "print('Test Accuracy:', lr_bow_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "b773906c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.92439024 0.92439024 0.92665037 0.92420538 0.92420538]\n",
      "Average CV Accuracy: 0.9247683224998509\n",
      "Test Accuracy: 0.9084315503173164\n"
     ]
    }
   ],
   "source": [
    "# Using TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# builds BOW features\n",
    "tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0)\n",
    "tv_train_features = tv.fit_transform(train_corpus)\n",
    "\n",
    "# transforms test_corpus into features\n",
    "tv_test_features = tv.transform(test_corpus)\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = linear_model.LogisticRegression(penalty='l2', max_iter=100, C=1, random_state=42)\n",
    "log_reg.fit(tv_train_features, train_label_nums)\n",
    "\n",
    "# Gets CV accuracy\n",
    "lr_tfidf_scores = cross_val_score(log_reg, tv_train_features, train_label_nums, cv=5)\n",
    "lr_tfidf_mean_score = np.mean(lr_tfidf_scores)\n",
    "print('CV Accuracy (5-fold):', lr_tfidf_scores) # 5-fold\n",
    "print('Average CV Accuracy:', lr_tfidf_mean_score) # Average\n",
    "\n",
    "# Model test accuracy\n",
    "lr_tfidf_score = log_reg.score(tv_test_features, test_label_nums)\n",
    "print('Test Accuracy:', lr_tfidf_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84158bc",
   "metadata": {},
   "source": [
    "<b>At the end of Chapter 5, the author uses a custom-built class to summarize model performance. This class doesnâ€™t actually exist (from the author) but you can make it a reality. Using the object you have from mnb_predictions, create something similar to the output on page 335.<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9d24fa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.99      0.96      1000\n",
      "           0       0.80      0.36      0.50       103\n",
      "\n",
      "    accuracy                           0.93      1103\n",
      "   macro avg       0.87      0.68      0.73      1103\n",
      "weighted avg       0.93      0.93      0.92      1103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Textbook uses *mnb_predictions = gs_mnb.predict(test_corpus)* for predicted_labels arg\n",
    "# y_pred from my model returns the same output, with respect to label names/nums.\n",
    "meu.display_classification_report(true_labels=test_label_nums,\n",
    "                                  predicted_labels=y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
